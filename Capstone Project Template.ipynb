{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "A team of Data Scientists has asked the following question: could the number of crimes committed in a city correlated to the average temperature and the immigration rates?\n",
    "\n",
    "**NOTE:** Not considering psychological or socioeconomic factors.\n",
    "\n",
    "To develop a pilot test, the Data Science team decided to take as a sample from one of the main cities in the United States, the city of Los Angeles California.\n",
    "\n",
    "To help this team of researchers, the Data Engineering team has been asked to be in charge of obtaining and preparing the data to carry out this analysis.\n",
    "\n",
    "This project was designed to execute the process to pull and transform the data needed for the Data Science team.\n",
    "\n",
    "The project follows the next steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Doing all imports and installs\n",
    "import pandas as pd\n",
    "\n",
    "import configparser\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, to_date\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, dayofweek, date_format\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope\n",
    "For this project the main idea is to create a ETL process to make sure Immigration, crime and temperature data match. This process will allow the Data Science team to test its hypothesis about the correlation between immigration, crime and temperature data.\n",
    "\n",
    "\n",
    "#### Describe and Gather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Initializing Spark session\n",
    "spark = SparkSession.builder\\\n",
    ".config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport()\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* #### Immigrtion Data\n",
    "Each report contains international visitor arrival statistics by world regions and select countries (including top 20), type of visa, mode of transportation, age groups, states visited (first intended address only), and the top ports of entry (for select countries).\n",
    "\n",
    "    Data and description retrieved from: \n",
    "    [Immigration data source](https://travel.trade.gov/research/reports/i94/historical/2016.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Setting the path for Immigration data\n",
    "i94_path = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "\n",
    "# Reading data\n",
    "df_i94 = spark.read.format('com.github.saurfang.sas.spark').load(i94_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>None</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20555.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9.247104e+10</td>\n",
       "      <td>00602</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NJ</td>\n",
       "      <td>20558.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9.247140e+10</td>\n",
       "      <td>00602</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NJ</td>\n",
       "      <td>20558.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9.247161e+10</td>\n",
       "      <td>00602</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9.247080e+10</td>\n",
       "      <td>00602</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20562.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9.247849e+10</td>\n",
       "      <td>00608</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN    None   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "5   18.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MI   \n",
       "6   19.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      NJ   \n",
       "7   20.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      NJ   \n",
       "8   21.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      NY   \n",
       "9   22.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      NY   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U     None   1979.0  10282016   None   None   \n",
       "1      NaN   ...           Y     None   1991.0       D/S      M   None   \n",
       "2  20691.0   ...        None        M   1961.0  09302016      M   None   \n",
       "3  20567.0   ...        None        M   1988.0  09302016   None   None   \n",
       "4  20567.0   ...        None        M   2012.0  09302016   None   None   \n",
       "5  20555.0   ...        None        M   1959.0  09302016   None   None   \n",
       "6  20558.0   ...        None        M   1953.0  09302016   None   None   \n",
       "7  20558.0   ...        None        M   1959.0  09302016   None   None   \n",
       "8  20553.0   ...        None        M   1970.0  09302016   None   None   \n",
       "9  20562.0   ...        None        M   1968.0  09302016   None   None   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0    None  1.897628e+09   None       B2  \n",
       "1    None  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "5      AZ  9.247104e+10  00602       B1  \n",
       "6      AZ  9.247140e+10  00602       B2  \n",
       "7      AZ  9.247161e+10  00602       B2  \n",
       "8      AZ  9.247080e+10  00602       B2  \n",
       "9      AZ  9.247849e+10  00608       B1  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizing Immigration data\n",
    "df_i94.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* #### LA Crime Data\n",
    "This dataset reflects incidents of crime in the City of Los Angeles from 2010 to 2019. This data is transcribed from original crime reports that are typed on paper and therefore there may be some inaccuracies within the data. Some location fields with missing data are noted as (0°, 0°). Address fields are only provided to the nearest hundred block in order to maintain privacy.\n",
    "\n",
    "    Data and description retrieved from:\n",
    "    [LA Crime data source](https://www.kaggle.com/chaitanyakck/crime-data-from-2020-to-present?select=Crime_Data_from_2020_to_Present.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Setting the path for Crimes in L.A. city data\n",
    "crimes_data_path = 'csv_data/LA_crime_data/Crime_Data_from_2010_to_2019.csv'\n",
    "\n",
    "# Reading data\n",
    "df_LA_crimes = spark.read.csv(crimes_data_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DR_NO</th>\n",
       "      <th>Date Rptd</th>\n",
       "      <th>DATE OCC</th>\n",
       "      <th>TIME OCC</th>\n",
       "      <th>AREA</th>\n",
       "      <th>AREA NAME</th>\n",
       "      <th>Rpt Dist No</th>\n",
       "      <th>Part 1-2</th>\n",
       "      <th>Crm Cd</th>\n",
       "      <th>Crm Cd Desc</th>\n",
       "      <th>...</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status Desc</th>\n",
       "      <th>Crm Cd 1</th>\n",
       "      <th>Crm Cd 2</th>\n",
       "      <th>Crm Cd 3</th>\n",
       "      <th>Crm Cd 4</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>Cross Street</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1307355</td>\n",
       "      <td>02/20/2010 12:00:00 AM</td>\n",
       "      <td>02/20/2010 12:00:00 AM</td>\n",
       "      <td>1350</td>\n",
       "      <td>13</td>\n",
       "      <td>Newton</td>\n",
       "      <td>1385</td>\n",
       "      <td>2</td>\n",
       "      <td>900</td>\n",
       "      <td>VIOLATION OF COURT ORDER</td>\n",
       "      <td>...</td>\n",
       "      <td>AA</td>\n",
       "      <td>Adult Arrest</td>\n",
       "      <td>900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>300 E  GAGE                         AV</td>\n",
       "      <td>None</td>\n",
       "      <td>33.9825</td>\n",
       "      <td>-118.2695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11401303</td>\n",
       "      <td>09/13/2010 12:00:00 AM</td>\n",
       "      <td>09/12/2010 12:00:00 AM</td>\n",
       "      <td>45</td>\n",
       "      <td>14</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>1485</td>\n",
       "      <td>2</td>\n",
       "      <td>740</td>\n",
       "      <td>VANDALISM - FELONY ($400 &amp; OVER, ALL CHURCH VA...</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>SEPULVEDA                    BL</td>\n",
       "      <td>MANCHESTER                   AV</td>\n",
       "      <td>33.9599</td>\n",
       "      <td>-118.3962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70309629</td>\n",
       "      <td>08/09/2010 12:00:00 AM</td>\n",
       "      <td>08/09/2010 12:00:00 AM</td>\n",
       "      <td>1515</td>\n",
       "      <td>13</td>\n",
       "      <td>Newton</td>\n",
       "      <td>1324</td>\n",
       "      <td>2</td>\n",
       "      <td>946</td>\n",
       "      <td>OTHER MISCELLANEOUS CRIME</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1300 E  21ST                         ST</td>\n",
       "      <td>None</td>\n",
       "      <td>34.0224</td>\n",
       "      <td>-118.2524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90631215</td>\n",
       "      <td>01/05/2010 12:00:00 AM</td>\n",
       "      <td>01/05/2010 12:00:00 AM</td>\n",
       "      <td>150</td>\n",
       "      <td>6</td>\n",
       "      <td>Hollywood</td>\n",
       "      <td>646</td>\n",
       "      <td>2</td>\n",
       "      <td>900</td>\n",
       "      <td>VIOLATION OF COURT ORDER</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>900</td>\n",
       "      <td>998.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CAHUENGA                     BL</td>\n",
       "      <td>HOLLYWOOD                    BL</td>\n",
       "      <td>34.1016</td>\n",
       "      <td>-118.3295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100100501</td>\n",
       "      <td>01/03/2010 12:00:00 AM</td>\n",
       "      <td>01/02/2010 12:00:00 AM</td>\n",
       "      <td>2100</td>\n",
       "      <td>1</td>\n",
       "      <td>Central</td>\n",
       "      <td>176</td>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>RAPE, ATTEMPTED</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8TH                          ST</td>\n",
       "      <td>SAN PEDRO                    ST</td>\n",
       "      <td>34.0387</td>\n",
       "      <td>-118.2488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100100506</td>\n",
       "      <td>01/05/2010 12:00:00 AM</td>\n",
       "      <td>01/04/2010 12:00:00 AM</td>\n",
       "      <td>1650</td>\n",
       "      <td>1</td>\n",
       "      <td>Central</td>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>442</td>\n",
       "      <td>SHOPLIFTING - PETTY THEFT ($950 &amp; UNDER)</td>\n",
       "      <td>...</td>\n",
       "      <td>AA</td>\n",
       "      <td>Adult Arrest</td>\n",
       "      <td>442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>700 W  7TH                          ST</td>\n",
       "      <td>None</td>\n",
       "      <td>34.0480</td>\n",
       "      <td>-118.2577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100100508</td>\n",
       "      <td>01/08/2010 12:00:00 AM</td>\n",
       "      <td>01/07/2010 12:00:00 AM</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>Central</td>\n",
       "      <td>182</td>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>BURGLARY FROM VEHICLE</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>PICO                         BL</td>\n",
       "      <td>GRAND                        AV</td>\n",
       "      <td>34.0389</td>\n",
       "      <td>-118.2643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100100509</td>\n",
       "      <td>01/09/2010 12:00:00 AM</td>\n",
       "      <td>01/08/2010 12:00:00 AM</td>\n",
       "      <td>2100</td>\n",
       "      <td>1</td>\n",
       "      <td>Central</td>\n",
       "      <td>157</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT</td>\n",
       "      <td>...</td>\n",
       "      <td>AA</td>\n",
       "      <td>Adult Arrest</td>\n",
       "      <td>230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>500    CROCKER                      ST</td>\n",
       "      <td>None</td>\n",
       "      <td>34.0435</td>\n",
       "      <td>-118.2427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100100510</td>\n",
       "      <td>01/09/2010 12:00:00 AM</td>\n",
       "      <td>01/09/2010 12:00:00 AM</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>Central</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>800 W  OLYMPIC                      BL</td>\n",
       "      <td>None</td>\n",
       "      <td>34.0450</td>\n",
       "      <td>-118.2640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100100511</td>\n",
       "      <td>01/09/2010 12:00:00 AM</td>\n",
       "      <td>01/06/2010 12:00:00 AM</td>\n",
       "      <td>2100</td>\n",
       "      <td>1</td>\n",
       "      <td>Central</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>341</td>\n",
       "      <td>THEFT-GRAND ($950.01 &amp; OVER)EXCPT,GUNS,FOWL,LI...</td>\n",
       "      <td>...</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "      <td>341</td>\n",
       "      <td>998.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>200 S  OLIVE                        ST</td>\n",
       "      <td>None</td>\n",
       "      <td>34.0538</td>\n",
       "      <td>-118.2488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DR_NO               Date Rptd                DATE OCC  TIME OCC  AREA   \\\n",
       "0    1307355  02/20/2010 12:00:00 AM  02/20/2010 12:00:00 AM      1350     13   \n",
       "1   11401303  09/13/2010 12:00:00 AM  09/12/2010 12:00:00 AM        45     14   \n",
       "2   70309629  08/09/2010 12:00:00 AM  08/09/2010 12:00:00 AM      1515     13   \n",
       "3   90631215  01/05/2010 12:00:00 AM  01/05/2010 12:00:00 AM       150      6   \n",
       "4  100100501  01/03/2010 12:00:00 AM  01/02/2010 12:00:00 AM      2100      1   \n",
       "5  100100506  01/05/2010 12:00:00 AM  01/04/2010 12:00:00 AM      1650      1   \n",
       "6  100100508  01/08/2010 12:00:00 AM  01/07/2010 12:00:00 AM      2005      1   \n",
       "7  100100509  01/09/2010 12:00:00 AM  01/08/2010 12:00:00 AM      2100      1   \n",
       "8  100100510  01/09/2010 12:00:00 AM  01/09/2010 12:00:00 AM       230      1   \n",
       "9  100100511  01/09/2010 12:00:00 AM  01/06/2010 12:00:00 AM      2100      1   \n",
       "\n",
       "   AREA NAME  Rpt Dist No  Part 1-2  Crm Cd  \\\n",
       "0     Newton         1385         2     900   \n",
       "1    Pacific         1485         2     740   \n",
       "2     Newton         1324         2     946   \n",
       "3  Hollywood          646         2     900   \n",
       "4    Central          176         1     122   \n",
       "5    Central          162         1     442   \n",
       "6    Central          182         1     330   \n",
       "7    Central          157         1     230   \n",
       "8    Central          171         1     230   \n",
       "9    Central          132         1     341   \n",
       "\n",
       "                                         Crm Cd Desc    ...    Status  \\\n",
       "0                           VIOLATION OF COURT ORDER    ...        AA   \n",
       "1  VANDALISM - FELONY ($400 & OVER, ALL CHURCH VA...    ...        IC   \n",
       "2                          OTHER MISCELLANEOUS CRIME    ...        IC   \n",
       "3                           VIOLATION OF COURT ORDER    ...        IC   \n",
       "4                                    RAPE, ATTEMPTED    ...        IC   \n",
       "5           SHOPLIFTING - PETTY THEFT ($950 & UNDER)    ...        AA   \n",
       "6                              BURGLARY FROM VEHICLE    ...        IC   \n",
       "7     ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT    ...        AA   \n",
       "8     ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT    ...        IC   \n",
       "9  THEFT-GRAND ($950.01 & OVER)EXCPT,GUNS,FOWL,LI...    ...        IC   \n",
       "\n",
       "    Status Desc Crm Cd 1 Crm Cd 2  Crm Cd 3 Crm Cd 4  \\\n",
       "0  Adult Arrest      900      NaN      None     None   \n",
       "1   Invest Cont      740      NaN      None     None   \n",
       "2   Invest Cont      946      NaN      None     None   \n",
       "3   Invest Cont      900    998.0      None     None   \n",
       "4   Invest Cont      122      NaN      None     None   \n",
       "5  Adult Arrest      442      NaN      None     None   \n",
       "6   Invest Cont      330      NaN      None     None   \n",
       "7  Adult Arrest      230      NaN      None     None   \n",
       "8   Invest Cont      230      NaN      None     None   \n",
       "9   Invest Cont      341    998.0      None     None   \n",
       "\n",
       "                                  LOCATION                     Cross Street  \\\n",
       "0   300 E  GAGE                         AV                             None   \n",
       "1          SEPULVEDA                    BL  MANCHESTER                   AV   \n",
       "2  1300 E  21ST                         ST                             None   \n",
       "3          CAHUENGA                     BL  HOLLYWOOD                    BL   \n",
       "4          8TH                          ST  SAN PEDRO                    ST   \n",
       "5   700 W  7TH                          ST                             None   \n",
       "6          PICO                         BL  GRAND                        AV   \n",
       "7   500    CROCKER                      ST                             None   \n",
       "8   800 W  OLYMPIC                      BL                             None   \n",
       "9   200 S  OLIVE                        ST                             None   \n",
       "\n",
       "       LAT       LON  \n",
       "0  33.9825 -118.2695  \n",
       "1  33.9599 -118.3962  \n",
       "2  34.0224 -118.2524  \n",
       "3  34.1016 -118.3295  \n",
       "4  34.0387 -118.2488  \n",
       "5  34.0480 -118.2577  \n",
       "6  34.0389 -118.2643  \n",
       "7  34.0435 -118.2427  \n",
       "8  34.0450 -118.2640  \n",
       "9  34.0538 -118.2488  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizing LA Crimes data\n",
    "df_LA_crimes.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* #### World Temperature Data\n",
    "\n",
    "    Daily temperature data from ERA5 reanalysis data from Copernicus Climate Service. It's time-series value in degrees Celsius, for 1000 most populous cities in the world, from Jan-01-1980 to Sept-30-2020.\n",
    "\n",
    "    Data and description retreived from:\n",
    "    [Temperature data source](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Setting the path for Top Cities Temperature data\n",
    "cities_temp_path = 'csv_data/Temp_data/daily_temperature_1000_cities_1980_2020.csv'\n",
    "\n",
    "# Reading data\n",
    "df_cities_temp = spark.read.csv(cities_temp_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>city</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>New York</td>\n",
       "      <td>Mexico City</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Shanghai</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>...</td>\n",
       "      <td>Bilāspur</td>\n",
       "      <td>Sargodha</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Tinnevelly</td>\n",
       "      <td>Cancún</td>\n",
       "      <td>Yangzhou</td>\n",
       "      <td>Novokuznetsk</td>\n",
       "      <td>Latakia</td>\n",
       "      <td>Heroica Matamoros</td>\n",
       "      <td>Göteborg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>city_ascii</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>New York</td>\n",
       "      <td>Mexico City</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Shanghai</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>...</td>\n",
       "      <td>Bilaspur</td>\n",
       "      <td>Sargodha</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Tinnevelly</td>\n",
       "      <td>Cancun</td>\n",
       "      <td>Yangzhou</td>\n",
       "      <td>Novokuznetsk</td>\n",
       "      <td>Latakia</td>\n",
       "      <td>Heroica Matamoros</td>\n",
       "      <td>Goteborg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lat</td>\n",
       "      <td>35.685</td>\n",
       "      <td>40.6943</td>\n",
       "      <td>19.4424</td>\n",
       "      <td>19.017</td>\n",
       "      <td>-23.5587</td>\n",
       "      <td>28.67</td>\n",
       "      <td>31.2165</td>\n",
       "      <td>22.495</td>\n",
       "      <td>34.1139</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0904</td>\n",
       "      <td>32.0854</td>\n",
       "      <td>51.3354</td>\n",
       "      <td>8.7304</td>\n",
       "      <td>21.17</td>\n",
       "      <td>32.4</td>\n",
       "      <td>53.75</td>\n",
       "      <td>35.54</td>\n",
       "      <td>25.88</td>\n",
       "      <td>57.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lng</td>\n",
       "      <td>139.7514</td>\n",
       "      <td>-73.9249</td>\n",
       "      <td>-99.131</td>\n",
       "      <td>72.857</td>\n",
       "      <td>-46.625</td>\n",
       "      <td>77.23</td>\n",
       "      <td>121.4365</td>\n",
       "      <td>88.3247</td>\n",
       "      <td>-118.4068</td>\n",
       "      <td>...</td>\n",
       "      <td>82.16</td>\n",
       "      <td>72.675</td>\n",
       "      <td>12.41</td>\n",
       "      <td>77.69</td>\n",
       "      <td>-86.83</td>\n",
       "      <td>119.43</td>\n",
       "      <td>87.115</td>\n",
       "      <td>35.78</td>\n",
       "      <td>-97.5</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>country</td>\n",
       "      <td>Japan</td>\n",
       "      <td>United States</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>India</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>India</td>\n",
       "      <td>China</td>\n",
       "      <td>India</td>\n",
       "      <td>United States</td>\n",
       "      <td>...</td>\n",
       "      <td>India</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>Germany</td>\n",
       "      <td>India</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>China</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Syria</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iso2</td>\n",
       "      <td>JP</td>\n",
       "      <td>US</td>\n",
       "      <td>MX</td>\n",
       "      <td>IN</td>\n",
       "      <td>BR</td>\n",
       "      <td>IN</td>\n",
       "      <td>CN</td>\n",
       "      <td>IN</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>IN</td>\n",
       "      <td>PK</td>\n",
       "      <td>DE</td>\n",
       "      <td>IN</td>\n",
       "      <td>MX</td>\n",
       "      <td>CN</td>\n",
       "      <td>RU</td>\n",
       "      <td>SY</td>\n",
       "      <td>MX</td>\n",
       "      <td>SE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>iso3</td>\n",
       "      <td>JPN</td>\n",
       "      <td>USA</td>\n",
       "      <td>MEX</td>\n",
       "      <td>IND</td>\n",
       "      <td>BRA</td>\n",
       "      <td>IND</td>\n",
       "      <td>CHN</td>\n",
       "      <td>IND</td>\n",
       "      <td>USA</td>\n",
       "      <td>...</td>\n",
       "      <td>IND</td>\n",
       "      <td>PAK</td>\n",
       "      <td>DEU</td>\n",
       "      <td>IND</td>\n",
       "      <td>MEX</td>\n",
       "      <td>CHN</td>\n",
       "      <td>RUS</td>\n",
       "      <td>SYR</td>\n",
       "      <td>MEX</td>\n",
       "      <td>SWE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>admin_name</td>\n",
       "      <td>Tōkyō</td>\n",
       "      <td>New York</td>\n",
       "      <td>Ciudad de México</td>\n",
       "      <td>Mahārāshtra</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Shanghai</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>California</td>\n",
       "      <td>...</td>\n",
       "      <td>Chhattīsgarh</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>Saxony</td>\n",
       "      <td>Tamil Nādu</td>\n",
       "      <td>Quintana Roo</td>\n",
       "      <td>Jiangsu</td>\n",
       "      <td>Kemerovskaya Oblast’</td>\n",
       "      <td>Al Lādhiqīyah</td>\n",
       "      <td>Tamaulipas</td>\n",
       "      <td>Västra Götaland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>capital</td>\n",
       "      <td>primary</td>\n",
       "      <td>None</td>\n",
       "      <td>primary</td>\n",
       "      <td>admin</td>\n",
       "      <td>admin</td>\n",
       "      <td>admin</td>\n",
       "      <td>admin</td>\n",
       "      <td>admin</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>minor</td>\n",
       "      <td>minor</td>\n",
       "      <td>None</td>\n",
       "      <td>minor</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>admin</td>\n",
       "      <td>minor</td>\n",
       "      <td>admin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>population</td>\n",
       "      <td>35676000.0</td>\n",
       "      <td>19354922.0</td>\n",
       "      <td>19028000.0</td>\n",
       "      <td>18978000.0</td>\n",
       "      <td>18845000.0</td>\n",
       "      <td>15926000.0</td>\n",
       "      <td>14987000.0</td>\n",
       "      <td>14787000.0</td>\n",
       "      <td>12815475.0</td>\n",
       "      <td>...</td>\n",
       "      <td>543454.0</td>\n",
       "      <td>542603.0</td>\n",
       "      <td>542529.0</td>\n",
       "      <td>542200.0</td>\n",
       "      <td>542043.0</td>\n",
       "      <td>539715.0</td>\n",
       "      <td>539616.0</td>\n",
       "      <td>539147.0</td>\n",
       "      <td>538785.0</td>\n",
       "      <td>537797.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          _c0           0              1                 2            3  \\\n",
       "0        city       Tokyo       New York       Mexico City       Mumbai   \n",
       "1  city_ascii       Tokyo       New York       Mexico City       Mumbai   \n",
       "2         lat      35.685        40.6943           19.4424       19.017   \n",
       "3         lng    139.7514       -73.9249           -99.131       72.857   \n",
       "4     country       Japan  United States            Mexico        India   \n",
       "5        iso2          JP             US                MX           IN   \n",
       "6        iso3         JPN            USA               MEX          IND   \n",
       "7  admin_name       Tōkyō       New York  Ciudad de México  Mahārāshtra   \n",
       "8     capital     primary           None           primary        admin   \n",
       "9  population  35676000.0     19354922.0        19028000.0   18978000.0   \n",
       "\n",
       "            4           5           6            7              8  \\\n",
       "0   São Paulo       Delhi    Shanghai      Kolkata    Los Angeles   \n",
       "1   Sao Paulo       Delhi    Shanghai      Kolkata    Los Angeles   \n",
       "2    -23.5587       28.67     31.2165       22.495        34.1139   \n",
       "3     -46.625       77.23    121.4365      88.3247      -118.4068   \n",
       "4      Brazil       India       China        India  United States   \n",
       "5          BR          IN          CN           IN             US   \n",
       "6         BRA         IND         CHN          IND            USA   \n",
       "7   São Paulo       Delhi    Shanghai  West Bengal     California   \n",
       "8       admin       admin       admin        admin           None   \n",
       "9  18845000.0  15926000.0  14987000.0   14787000.0     12815475.0   \n",
       "\n",
       "        ...                  990       991       992          993  \\\n",
       "0       ...             Bilāspur  Sargodha   Leipzig   Tinnevelly   \n",
       "1       ...             Bilaspur  Sargodha   Leipzig   Tinnevelly   \n",
       "2       ...              22.0904   32.0854   51.3354       8.7304   \n",
       "3       ...                82.16    72.675     12.41        77.69   \n",
       "4       ...                India  Pakistan   Germany        India   \n",
       "5       ...                   IN        PK        DE           IN   \n",
       "6       ...                  IND       PAK       DEU          IND   \n",
       "7       ...         Chhattīsgarh    Punjab    Saxony  Tamil Nādu    \n",
       "8       ...                 None     minor     minor         None   \n",
       "9       ...             543454.0  542603.0  542529.0     542200.0   \n",
       "\n",
       "            994       995                   996            997  \\\n",
       "0        Cancún  Yangzhou          Novokuznetsk        Latakia   \n",
       "1        Cancun  Yangzhou          Novokuznetsk        Latakia   \n",
       "2         21.17      32.4                 53.75          35.54   \n",
       "3        -86.83    119.43                87.115          35.78   \n",
       "4        Mexico     China                Russia          Syria   \n",
       "5            MX        CN                    RU             SY   \n",
       "6           MEX       CHN                   RUS            SYR   \n",
       "7  Quintana Roo   Jiangsu  Kemerovskaya Oblast’  Al Lādhiqīyah   \n",
       "8         minor      None                  None          admin   \n",
       "9      542043.0  539715.0              539616.0       539147.0   \n",
       "\n",
       "                 998              999  \n",
       "0  Heroica Matamoros         Göteborg  \n",
       "1  Heroica Matamoros         Goteborg  \n",
       "2              25.88            57.75  \n",
       "3              -97.5             12.0  \n",
       "4             Mexico           Sweden  \n",
       "5                 MX               SE  \n",
       "6                MEX              SWE  \n",
       "7         Tamaulipas  Västra Götaland  \n",
       "8              minor            admin  \n",
       "9           538785.0         537797.0  \n",
       "\n",
       "[10 rows x 1001 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizing Top Cities Temperature data\n",
    "df_cities_temp.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore and Clean the Data \n",
    "In this step the objective is to identify data quality issues, like missing values, duplicate data, etc. The data types most be consitent to make sure the Data Science Team will be able to use all data\n",
    "\n",
    "To clean the data sets the Data Engineering Team should drop duplicate records and make sure there is no missing values in columns that contain dates because this columns will be used to create the relations between data sets.\n",
    "\n",
    "The general process consists of 3 steps\n",
    "1. Exploring the data and counting records\n",
    "2. Dropping duplicates and missing values\n",
    "3. Changing data type if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Exploring Immigration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exploring df_i94 schema\n",
    "df_i94.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting total rows in df_i94 dataframe\n",
    "df_i94.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2953856"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping duplicated and missing values\n",
    "df_i94_cleaned = df_i94.dropDuplicates([\"cicid\"])\n",
    "df_i94_cleaned = df_i94.dropna(how=\"any\", subset=[\"cicid\", \"arrdate\", \"depdate\"])\n",
    "df_i94_cleaned.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Defining function to transform dates from sas files\n",
    "def convert_datetime(x):\n",
    "    \"\"\"\n",
    "    This function transforms dates in sas files into\n",
    "    date type.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        start = datetime(1960, 1, 1)\n",
    "        return start + timedelta(days=int(x))\n",
    "    except:\n",
    "        return None\n",
    "udf_datetime_from_sas = udf(lambda x: convert_datetime(x), T.DateType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: long (nullable = true)\n",
      " |-- i94yr: integer (nullable = true)\n",
      " |-- i94mon: integer (nullable = true)\n",
      " |-- i94cit: integer (nullable = true)\n",
      " |-- i94res: integer (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: date (nullable = true)\n",
      " |-- i94mode: integer (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: date (nullable = true)\n",
      " |-- i94bir: integer (nullable = true)\n",
      " |-- i94visa: integer (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: integer (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: long (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>692</td>\n",
       "      <td>692</td>\n",
       "      <td>XXX</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>None</td>\n",
       "      <td>1979</td>\n",
       "      <td>10282016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1897628485</td>\n",
       "      <td>None</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>254</td>\n",
       "      <td>276</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>1991</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3736796330</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>WAS</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>2016-08-25</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1961</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>666643185</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>NYC</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>92468461330</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>NYC</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>2012</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>92468463130</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid  i94yr  i94mon  i94cit  i94res i94port     arrdate  i94mode i94addr  \\\n",
       "0      6   2016       4     692     692     XXX  2016-04-29      NaN    None   \n",
       "1      7   2016       4     254     276     ATL  2016-04-07      1.0      AL   \n",
       "2     15   2016       4     101     101     WAS  2016-04-01      1.0      MI   \n",
       "3     16   2016       4     101     101     NYC  2016-04-01      1.0      MA   \n",
       "4     17   2016       4     101     101     NYC  2016-04-01      1.0      MA   \n",
       "\n",
       "      depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0        None   ...           U     None     1979  10282016   None   None   \n",
       "1        None   ...           Y     None     1991       D/S      M   None   \n",
       "2  2016-08-25   ...        None        M     1961  09302016      M   None   \n",
       "3  2016-04-23   ...        None        M     1988  09302016   None   None   \n",
       "4  2016-04-23   ...        None        M     2012  09302016   None   None   \n",
       "\n",
       "  airline       admnum  fltno visatype  \n",
       "0    None   1897628485   None       B2  \n",
       "1    None   3736796330  00296       F1  \n",
       "2      OS    666643185     93       B2  \n",
       "3      AA  92468461330  00199       B2  \n",
       "4      AA  92468463130  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing data types\n",
    "df_i94_cleaned = df_i94.withColumn(\"arrdate\", udf_datetime_from_sas(\"arrdate\"))\\\n",
    "                    .withColumn(\"depdate\", udf_datetime_from_sas(\"depdate\"))\\\n",
    "                    .withColumn(\"cicid\", df_i94[\"cicid\"].cast(\"bigint\"))\\\n",
    "                    .withColumn(\"i94yr\", df_i94[\"i94yr\"].cast(\"int\"))\\\n",
    "                    .withColumn(\"i94mon\", df_i94[\"i94mon\"].cast(\"int\"))\\\n",
    "                    .withColumn(\"i94cit\", df_i94[\"i94cit\"].cast(\"int\"))\\\n",
    "                    .withColumn(\"i94res\", df_i94[\"i94res\"].cast(\"int\"))\\\n",
    "                    .withColumn(\"i94mode\", df_i94[\"i94mode\"].cast(\"int\"))\\\n",
    "                    .withColumn(\"i94bir\", df_i94[\"i94bir\"].cast(\"int\"))\\\n",
    "                    .withColumn(\"i94visa\", df_i94[\"i94visa\"].cast(\"int\"))\\\n",
    "                    .withColumn(\"biryear\", df_i94[\"biryear\"].cast(\"int\"))\\\n",
    "                    .withColumn(\"admnum\", df_i94[\"admnum\"].cast(\"bigint\"))\n",
    "\n",
    "# Validating data type changes\n",
    "df_i94_cleaned.printSchema()\n",
    "\n",
    "df_i94_cleaned.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Exploring LA Crime Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DR_NO: integer (nullable = true)\n",
      " |-- Date Rptd: string (nullable = true)\n",
      " |-- DATE OCC: string (nullable = true)\n",
      " |-- TIME OCC: integer (nullable = true)\n",
      " |-- AREA : integer (nullable = true)\n",
      " |-- AREA NAME: string (nullable = true)\n",
      " |-- Rpt Dist No: integer (nullable = true)\n",
      " |-- Part 1-2: integer (nullable = true)\n",
      " |-- Crm Cd: integer (nullable = true)\n",
      " |-- Crm Cd Desc: string (nullable = true)\n",
      " |-- Mocodes: string (nullable = true)\n",
      " |-- Vict Age: integer (nullable = true)\n",
      " |-- Vict Sex: string (nullable = true)\n",
      " |-- Vict Descent: string (nullable = true)\n",
      " |-- Premis Cd: integer (nullable = true)\n",
      " |-- Premis Desc: string (nullable = true)\n",
      " |-- Weapon Used Cd: integer (nullable = true)\n",
      " |-- Weapon Desc: string (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Status Desc: string (nullable = true)\n",
      " |-- Crm Cd 1: integer (nullable = true)\n",
      " |-- Crm Cd 2: integer (nullable = true)\n",
      " |-- Crm Cd 3: integer (nullable = true)\n",
      " |-- Crm Cd 4: integer (nullable = true)\n",
      " |-- LOCATION: string (nullable = true)\n",
      " |-- Cross Street: string (nullable = true)\n",
      " |-- LAT: double (nullable = true)\n",
      " |-- LON: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exploring df_LA_crimes schema\n",
    "df_LA_crimes.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2116239"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting total rows in df_LA_crimes dataframe\n",
    "df_LA_crimes.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2116239"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping duplicated and missing values\n",
    "df_LA_crimes_cleaned = df_LA_crimes.dropDuplicates([\"DR_NO\"])\n",
    "df_LA_crimes_cleaned = df_LA_crimes.dropna(how=\"any\", subset=[\"DR_NO\", \"DATE OCC\"])\n",
    "df_LA_crimes_cleaned.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DR_NO: long (nullable = true)\n",
      " |-- Date Rptd: date (nullable = true)\n",
      " |-- DATE OCC: date (nullable = true)\n",
      " |-- TIME OCC: integer (nullable = true)\n",
      " |-- AREA : integer (nullable = true)\n",
      " |-- AREA NAME: string (nullable = true)\n",
      " |-- Rpt Dist No: integer (nullable = true)\n",
      " |-- Part 1-2: integer (nullable = true)\n",
      " |-- Crm Cd: integer (nullable = true)\n",
      " |-- Crm Cd Desc: string (nullable = true)\n",
      " |-- Mocodes: string (nullable = true)\n",
      " |-- Vict Age: integer (nullable = true)\n",
      " |-- Vict Sex: string (nullable = true)\n",
      " |-- Vict Descent: string (nullable = true)\n",
      " |-- Premis Cd: integer (nullable = true)\n",
      " |-- Premis Desc: string (nullable = true)\n",
      " |-- Weapon Used Cd: integer (nullable = true)\n",
      " |-- Weapon Desc: string (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Status Desc: string (nullable = true)\n",
      " |-- Crm Cd 1: integer (nullable = true)\n",
      " |-- Crm Cd 2: integer (nullable = true)\n",
      " |-- Crm Cd 3: integer (nullable = true)\n",
      " |-- Crm Cd 4: integer (nullable = true)\n",
      " |-- LOCATION: string (nullable = true)\n",
      " |-- Cross Street: string (nullable = true)\n",
      " |-- LAT: double (nullable = true)\n",
      " |-- LON: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Changing data types\n",
    "df_LA_crimes_cleaned = df_LA_crimes_cleaned.withColumn(\"Date Rptd\", to_date(col(\"Date Rptd\"), \"MM/dd/yyyy\"))\\\n",
    "                                           .withColumn(\"DATE OCC\", to_date(col(\"DATE OCC\"), \"MM/dd/yyyy\"))\\\n",
    "                                           .withColumn(\"DR_NO\", df_LA_crimes_cleaned[\"DR_NO\"].cast(\"bigint\"))\\\n",
    "\n",
    "# Validating data type changes\n",
    "df_LA_crimes_cleaned.printSchema()\n",
    "\n",
    "#df_LA_crimes_cleaned.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Exploring Top Cities Temperatures Data\n",
    "\n",
    "1. Columns are named with numbers from 1 to 999. For this project it is required LA data so the columns needed are \"_c0\" and \"8\", the remaining columns can be dropped\n",
    "\n",
    "2. First records have informative data not needed for this project so they can be filtered out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Creating a list of columns that will be included\n",
    "columns_to_keep = [\"_c0\", \"8\"]\n",
    "\n",
    "# Creating a list of rows to filter\n",
    "no_valid_values = [\"city\", \"city_ascii\", \"lat\", \"lng\", \"country\", \"iso2\", \"iso3\", \"admin_name\", \"capital\", \"population\", \"id\", \"datetime\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Dropping all columns except for \"_c0\" and \"8\"\n",
    "#df_LA_temp = df_cities_temp.drop(*columns_to_drop)\n",
    "df_LA_temp = df_cities_temp.select(*columns_to_keep)\n",
    "\n",
    "# Filtering out records included in no_valid_values\n",
    "df_LA_temp_cleaned = df_LA_temp.filter(~df_LA_temp._c0.isin(no_valid_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- 8: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exploring LA Temperaure schema\n",
    "df_LA_temp_cleaned.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14884"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting total rows in df_LA_temp_cleaned dataframe\n",
    "df_LA_temp_cleaned.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14884"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping duplicated and missing values\n",
    "df_LA_temp_cleaned = df_LA_temp_cleaned.dropDuplicates([\"_c0\"])\n",
    "df_LA_temp_cleaned = df_LA_temp_cleaned.dropna(how=\"any\", subset=[\"_c0\", \"8\"])\n",
    "df_LA_temp_cleaned.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: date (nullable = true)\n",
      " |-- 8: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Changing data types\n",
    "df_LA_temp_cleaned = df_LA_temp_cleaned.withColumn(\"_c0\", df_LA_temp_cleaned[\"_c0\"].cast(DateType()))\\\n",
    "                                       .withColumn(\"8\", df_LA_temp_cleaned[\"8\"].cast(\"double\"))\n",
    "\n",
    "# Validating data type changes\n",
    "df_LA_temp_cleaned.printSchema()\n",
    "\n",
    "#df_LA_temp_cleaned.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "In this step the main idea is to configure a set of attributes (in this case immigration rates and temperature) to validate if they have an influence on the number of crimes committed.\n",
    "\n",
    "That's the reason why Data Engineering and Data Science teams select the Immigration data and LA temperature data to create the dimensional tables and LA Crimes data to create the fact table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Dimension tables**:\n",
    "\n",
    "- immigration_table\n",
    "    - date_arr\n",
    "    - date_dep\n",
    "    - id_imm\n",
    "    - year_arr\n",
    "    - month_arr\n",
    "    - port_arr\n",
    "    - trans_mode\n",
    "    - state_arr\n",
    "    - visa_code\n",
    "    - visa_type\n",
    "    - visa_issued\n",
    "    - imm_age\n",
    "    - imm_gender\n",
    "    - imm_city_birth\n",
    "    - imm_city_res\n",
    "    \n",
    "    \n",
    "- LA_temp_table\n",
    "    - date\n",
    "    - avg_temp\n",
    "    \n",
    "    \n",
    "- time_table\n",
    "    - date\n",
    "    - year\n",
    "    - month\n",
    "    - week\n",
    "    - weekday\n",
    "    - day\n",
    "    \n",
    "**Fact table**:\n",
    "\n",
    "- LA_crime_table\n",
    "    - id_LA_crime\n",
    "    - date_occ\n",
    "    - date_rep\n",
    "    - time_occ\n",
    "    - area_name\n",
    "    - crime_com_desc\n",
    "    - modus_op_code\n",
    "    - vict_age\n",
    "    - vict_gender\n",
    "    - vict_descent\n",
    "    - crime_place_desc\n",
    "    - weapon_used_desc\n",
    "    - status_case_desc\n",
    "    - latitude\n",
    "    - longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "This pipeline should:\n",
    "1. Load the datasets cleaned\n",
    "2. Filter values in the immigration dataset to include only California info.\n",
    "3. Create the dimension tables (immigration_dim_table, LA_temp_dim_table and time_dim_table)\n",
    "4. Create fact table (LA_crime_fact_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "This step creates the data model previously defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "output_data = \"data_transformed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_immigration_data(input_data, output_data):\n",
    "    \"\"\"\n",
    "    This function loads the immigration data \n",
    "    previously cleaned and transform it to meake \n",
    "    sure only includes the Los Angeles data and \n",
    "    finally, creates the .parquet files\n",
    "    \"\"\"\n",
    "    \n",
    "    # Getting immigration data\n",
    "    df_i94_cleaned = input_data\n",
    "    \n",
    "    # Filtering i94addr = CA\n",
    "    df_i94_cleaned = df_i94_cleaned.filter(df_i94_cleaned.i94addr == \"CA\")\n",
    "\n",
    "    # Creating the year and month columns from depdate\n",
    "    df_i94_cleaned = df_i94_cleaned.withColumn(\"month_dep\", month(\"depdate\")) \\\n",
    "                                   .withColumn(\"year_dep\", year(\"depdate\"))\n",
    "    \n",
    "    # Creating immigration dimension table\n",
    "    immigration_dim_table = df_i94_cleaned.select(\n",
    "                                          col(\"cicid\").alias(\"id_imm\"),\n",
    "                                          col(\"i94port\").alias(\"port_arr\"),\n",
    "                                          col(\"i94mode\").alias(\"trans_mode\"),\n",
    "                                          col(\"i94addr\").alias(\"state_arr\"),\n",
    "                                          col(\"i94visa\").alias(\"visa_code\"),\n",
    "                                          col(\"visatype\").alias(\"visa_type\"),\n",
    "                                          col(\"biryear\").alias(\"imm_age\"),\n",
    "                                          col(\"gender\").alias(\"imm_gender\"),\n",
    "                                          col(\"i94cit\").alias(\"imm_city_birth\"),\n",
    "                                          col(\"i94res\").alias(\"imm_city_res\"),\n",
    "                                          col(\"arrdate\").alias(\"date_arr\"),\n",
    "                                          col(\"i94yr\").alias(\"year_arr\"),\n",
    "                                          col(\"i94mon\").alias(\"month_arr\"),\n",
    "                                          col(\"depdate\").alias(\"date_dep\"),\n",
    "                                          col(\"year_dep\"),\n",
    "                                          col(\"month_dep\")) \\\n",
    "                                          .dropDuplicates()\n",
    "    \n",
    "    # Writting immigration dimension table to parquet files partitioned by year_dep and month_dep\n",
    "    immigration_dim_table.write.partitionBy(\"year_dep\", \"month_dep\").parquet(os.path.join(output_data, \"immigration.parquet\"), \"overwrite\")\n",
    "    \n",
    "    # Printing the final schema\n",
    "    #print(immigration_dim_table.printSchema())\n",
    "    \n",
    "    return immigration_dim_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_temperature_data(input_data, output_data):\n",
    "    \"\"\"\n",
    "    This function loads the temperature data \n",
    "    previously cleaned, transforms it and finally,\n",
    "    creates the .parquet files\n",
    "    \"\"\"\n",
    "    \n",
    "    # Getting temperature data\n",
    "    df_LA_temp = input_data\n",
    "    \n",
    "    # Creating LA temperature dimension table\n",
    "    LA_temp_dim_table = df_LA_temp.select(\n",
    "                                          col(\"_c0\").alias(\"date\"),\n",
    "                                          col(\"8\").alias(\"avg_temp\")) \\\n",
    "                                         .dropDuplicates()\n",
    "    \n",
    "    # Writting temperature dimension table to parquet files\n",
    "    LA_temp_dim_table.write.parquet(os.path.join(output_data, \"temperature.parquet\"), \"overwrite\")\n",
    "    \n",
    "    # Printing the final schema\n",
    "    #print(LA_temp_dim_table.printSchema())\n",
    "    \n",
    "    return LA_temp_dim_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_crimes_data(input_data, output_data):\n",
    "    \"\"\"\n",
    "    This function loads the LA crimes data \n",
    "    previously cleaned,transforms it into time \n",
    "    dimension table and crimes fact table and finally, \n",
    "    creates the .parquet files\n",
    "    \"\"\"\n",
    "    \n",
    "    # Getting LA crimes data\n",
    "    df_LA_crimes_cleaned = input_data\n",
    "    \n",
    "    # Creating the year, month, week, weekday and day columns from DATE OCC\n",
    "    df_LA_crimes_cleaned = df_LA_crimes_cleaned.withColumn(\"year\", year(\"DATE OCC\")) \\\n",
    "                                               .withColumn(\"month\", month(\"DATE OCC\")) \\\n",
    "                                               .withColumn(\"week\", weekofyear(\"DATE OCC\")) \\\n",
    "                                               .withColumn(\"weekday\", dayofweek(\"DATE OCC\")) \\\n",
    "                                               .withColumn(\"day\", dayofmonth(\"DATE OCC\"))\n",
    "    \n",
    "    # Creating time dimension table\n",
    "    time_dim_table = df_LA_crimes_cleaned.select(\n",
    "                                                 col(\"DATE OCC\").alias(\"date\"),\n",
    "                                                 col(\"year\"),\n",
    "                                                 col(\"month\"),\n",
    "                                                 col(\"week\"),\n",
    "                                                 col(\"weekday\"),\n",
    "                                                 col(\"day\")) \\\n",
    "                                                 .dropDuplicates()\n",
    "    \n",
    "    # Writting crimes fact table to parquet files partitioned by year_occ and month_occ\n",
    "    time_dim_table.write.partitionBy(\"year\", \"month\").parquet(os.path.join(output_data, \"time.parquet\"), \"overwrite\")\n",
    "    \n",
    "    # Printing the final schema\n",
    "    #print(time_dim_table.printSchema())\n",
    "    \n",
    "    # Creating LA temperature fact table\n",
    "    LA_crimes_fact_table = df_LA_crimes_cleaned.select(\n",
    "                                                      col(\"DR_NO\").alias(\"id_crime\"),\n",
    "                                                      col(\"DATE Rptd\").alias(\"date_rptd\"),\n",
    "                                                      col(\"TIME OCC\").alias(\"hour_occ\"),\n",
    "                                                      col(\"AREA NAME\").alias(\"area_name\"),\n",
    "                                                      col(\"Crm Cd desc\").alias(\"crime_com_desc\"),\n",
    "                                                      col(\"Mocodes\").alias(\"modus_op_code\"),\n",
    "                                                      col(\"Vict Age\").alias(\"vict_age\"),\n",
    "                                                      col(\"Vict Sex\").alias(\"vict_gender\"),\n",
    "                                                      col(\"Vict Descent\").alias(\"vict_descent_code\"),\n",
    "                                                      col(\"Premis Desc\").alias(\"crime_place_desc\"),\n",
    "                                                      col(\"Weapon Desc\").alias(\"weapon_used_desc\"),\n",
    "                                                      col(\"Status Desc\").alias(\"status_case_desc\"),\n",
    "                                                      col(\"LAT\").alias(\"latitude\"),\n",
    "                                                      col(\"LON\").alias(\"longitude\"),\n",
    "                                                      col(\"DATE OCC\").alias(\"date_occ\"),\n",
    "                                                      col(\"year\").alias(\"year_occ\"),\n",
    "                                                      col(\"month\").alias(\"month_occ\")) \\\n",
    "                                                     .dropDuplicates()\n",
    "    \n",
    "    # Writting crimes fact table to parquet files partitioned by year_occ and month_occ\n",
    "    LA_crimes_fact_table.write.partitionBy(\"year_occ\", \"month_occ\").parquet(os.path.join(output_data, \"crimes.parquet\"), \"overwrite\")\n",
    "    \n",
    "    # Printing the final schema\n",
    "    #print(LA_crimes_fact_table.printSchema())\n",
    "    \n",
    "    return time_dim_table, LA_crimes_fact_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_dim_table = process_immigration_data(df_i94_cleaned, output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "LA_temp_dim_table = process_temperature_data(df_LA_temp_cleaned, output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "time_dim_table, LA_crimes_fact_table = process_crimes_data(df_LA_crimes_cleaned, output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Creating a dictionary of names and tables\n",
    "dict_tables = {\n",
    "               \"immigration_dim_table\": immigration_dim_table, \n",
    "               \"LA_temp_dim_table\": LA_temp_dim_table, \n",
    "               \"time_dim_table\": time_dim_table, \n",
    "               \"LA_crimes_fact_table\": LA_crimes_fact_table\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Creating a function to validate id's are unique values\n",
    "def data_quality_unique_key(tables):\n",
    "    \"\"\"\n",
    "    This function validates if id column\n",
    "    in a table is unique.\n",
    "    \"\"\"\n",
    "    for name, table in tables.items():\n",
    "        col_name = table.schema.names\n",
    "        if table.count() & table.count() > table.dropDuplicates([col_name[0]]).count():\n",
    "            print(\"Test failed...\")\n",
    "            print(f\"{name} has duplicated values in ID column\")\n",
    "        else:\n",
    "            print(\"Test passed...\")\n",
    "            print(f\"{name} has no duplicated values in ID column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed...\n",
      "immigration_dim_table has no duplicated values in ID column\n",
      "Test passed...\n",
      "LA_temp_dim_table has no duplicated values in ID column\n",
      "Test passed...\n",
      "time_dim_table has no duplicated values in ID column\n",
      "Test passed...\n",
      "LA_crimes_fact_table has no duplicated values in ID column\n"
     ]
    }
   ],
   "source": [
    "data_quality_unique_key(dict_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Creating a function to validate the completeness of tables\n",
    "def data_quality_completeness(tables):\n",
    "    \"\"\"\n",
    "    This function validates if table exists\n",
    "    and if it contains records.\n",
    "    \"\"\"\n",
    "    for name, table in tables.items():\n",
    "        try:\n",
    "            if table.count():\n",
    "                records = table.count()\n",
    "                if records != 0:\n",
    "                    print(\"Test passed...\")\n",
    "                    print(f\"{name} exists and it has {records} records\")\n",
    "                else:\n",
    "                    print(\"Test failed...\")\n",
    "                    print(f\"{name} has zero records\")\n",
    "        except:\n",
    "            print(\"Test failed...\")\n",
    "            print(f\"{name} does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed...\n",
      "immigration_dim_table exists and it has 470386 records\n",
      "Test passed...\n",
      "LA_temp_dim_table exists and it has 14884 records\n",
      "Test passed...\n",
      "time_dim_table exists and it has 3652 records\n",
      "Test passed...\n",
      "LA_crimes_fact_table exists and it has 2116239 records\n"
     ]
    }
   ],
   "source": [
    "data_quality_completeness(dict_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "The data dictionary provides a brief description of data used in the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "immigration_dim_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "\n",
    "| Value | Description |\n",
    "| --- | --- |\n",
    "|date_arr | Date when immigrant arrived (yyyy-mmdd) |\n",
    "date_dep | Date when immigrant departured (yyyy-mmdd) |\n",
    "id_imm | Number to identify the record |\n",
    "year_arr | Year when immigrant arrived |\n",
    "month_arr | Month when immigrant arrived (numeric) |\n",
    "port_arr | Port where immigrant arrived |\n",
    "trans_mode | Transport mode (1 = \"Air\"; 2 = \"Sea\"; 3 = \"Land\"; 4 = \"Not Reported\") |\n",
    "state_arr | State where immigrant arrived |\n",
    "visa_code | Visa codes (1 = \"Business\"; 2 = \"Pleasure\"; 3 = \"Student\" |\n",
    "visa_type | Class of admission legally admitting the non-immigrant to temporarily stayed in U.S. |\n",
    "visa_issued | Department of State where Visa was issued |\n",
    "imm_age | Immigrant age |\n",
    "imm_gender | Immigrant gender |\n",
    "imm_city_birth | Immigrant city of birth in code |\n",
    "imm_city_res | Immigrant city of residence in code |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "LA_temperature_dim_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "| Value | Description |\n",
    "| --- | --- |\n",
    "| date | Date of temperature recorded |\n",
    "| avg_temp| Average of temperatures |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "time_dim_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "| Value | Description |\n",
    "| --- | --- |\n",
    "| year | Year |\n",
    "| month | Month (numeric) |\n",
    "| week | Week of year (numeric) |\n",
    "| weekday | Day of the week (numeric) |\n",
    "| day | Day of month (numeric) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "LA_crimes_fact_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "| Value | Description |\n",
    "| --- | --- |\n",
    "| id_crime | Number to identify the record |\n",
    "| date_rptd | Date when the crime reported (yyyy-mm-dd) |\n",
    "| date_occ | Date when the crime occurred (yyyy-mm-dd) |\n",
    "| hour_occ | Hour when the crime occurred |\n",
    "| area_name | The 21 Geographic Areas or Patrol Divisions |\n",
    "| crime_com_desc | Description of the crime commited |\n",
    "| modus_op_code | Modus Operandi code |\n",
    "| vict_age | Victim age |\n",
    "| vict_gender | Victim gender (F = \"Female\"; M = \"Male\"; X = \"Unknown\") |\n",
    "| vict_descent_code | Victim descent (A = \"Other Asian\"; B = \"Black\"; C = \"Chinese\"; D = \"Cambodian\"; F = \"Filipino\"; G = \"Guamanian\"; H = \"Hispanic/Latin/Mexican\"; I = \"American Indian/Alaskan Native\"; J = \"Japanese\"; K = \"Korean\"; L = \"Laotian\"; O = \"Other\"; P = \"Pacific Islander\"; S = \"Samoan\"; U = \"Hawaiian\"; V = \"Vietnamese\"; W = \"White\"; X = \"Unknown\"; Z = \"Asian Indian\") |\n",
    "| crime_place_desc | The type of structure, vehicle, or location where the crime occurred |\n",
    "| weapon_used_desc | The type of weapon used in the crime |\n",
    "| status_case_desc | Status of the case. (IC is the default) |\n",
    "| latitude | Latiude coordinates |\n",
    "| longitude | Longitude coordinates |\n",
    "| year_occ | Year when the crime occurred |\n",
    "| month_occ | Month when the crime occurred (numeric) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "\n",
    "This project uses Apache Spark because it is a technology built and optimized for processing huge amounts of data within a fast way, it manages easily data formats (SAS, CSV, JSON, parquet), it can read in data from other sources as well (such as Amazon S3). \n",
    "\n",
    "Considering this project is not intended to show data in real-time, and Immigration/Crime data sources were built on a monthly basis, the Data Engineering team decided that data will be refreshed by month.\n",
    "                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### The data was increased by 100x.\n",
    "\n",
    "There are many big data frameworks that could handle huge amounts of data; selecting one will depend on many factors.\n",
    "For this particular project Apache Spark could be a good solution because we are not working with stream data and Spark is faster than Hadoop.\n",
    "Also, it can be mentioned that there are options that allow us to manage in an easy way the increments of data; one of these platforms is AWS EMR among others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### The data populates a dashboard that must be updated on a daily basis by 7 am every day.\n",
    "\n",
    "One of the most popular technologies for running pipelines on a schedule is Apache Airflow. \n",
    "This tool provides a control dashboard for users and maintainers. Also, it comes with many Hooks that can be integrated with common systems (HttpHook, PostgresHook, MySqlHook, SlackHook, PrestoHook, etc.)\n",
    "For this particular project implementing Apache Airflow could handle tasks scheduled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### The database needed to be accessed by 100+ people.\n",
    "\n",
    "Data warehouse in cloud is one of the best options for accessing databases simultaneously by a lot of people. Technologies like Redshift, BigQuery, Teradata, Aster, Oracle ExaData or Azure, paralellize the execution of one query on multiple CPU/machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
